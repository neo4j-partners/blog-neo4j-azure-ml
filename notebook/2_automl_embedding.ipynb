{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rQ6G65n6OxV"
      },
      "source": [
        "# Automated ML Embedding\n",
        "In this notebook, we'll use Azure ML to train a model using our graph embedding as an additional feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install graphdatascience\n",
        "%pip install azure-ai-ml\n",
        "%pip install azureml-mlflow\n",
        "%pip install mlflow\n",
        "%pip install mltable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Azure ML Connection\n",
        "Let's setup our Azure ML connection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "gather": {
          "logged": 1669345050388
        }
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.identity import AzureCliCredential\n",
        "from azure.ai.ml import automl, Input, MLClient\n",
        "\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.automl import (\n",
        "    classification,\n",
        "    ClassificationPrimaryMetrics,\n",
        "    ClassificationModels,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Workspace details\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../configuration.ipynb) for more details on how to configure credentials and connect to a workspace.\n",
        "\n",
        "By default, we try to use the by default workspace configuration (available out-of-the-box in Compute Instances) or from any Config.json file you might have copied into the folders structure.\n",
        "If no Config.json is found, then you need to manually introduce the subscription_id, resource_group and workspace when creating MLClient ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "gather": {
          "logged": 1669345052512
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "credential = DefaultAzureCredential()\n",
        "ml_client = None\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    # Enter details of your AML workspace\n",
        "    subscription_id = \"<YOUR_SUBSCRIPTION_ID>\"\n",
        "    resource_group = \"<YOUR_RESOURCE_GROUP>\"\n",
        "    workspace = \"<YOUR_AZURE_ML_WORKSPACE>\"\n",
        "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669345058689
        }
      },
      "outputs": [],
      "source": [
        "workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
        "\n",
        "output = {}\n",
        "output[\"Workspace\"] = ml_client.workspace_name\n",
        "output[\"Subscription ID\"] = ml_client.connections._subscription_id\n",
        "output[\"Resource Group\"] = workspace.resource_group\n",
        "output[\"Location\"] = workspace.location\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload Training Data MLTable\n",
        "Now we're going to upload the training data to Azureml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "gather": {
          "logged": 1669345064798
        }
      },
      "outputs": [],
      "source": [
        "# MLTable definition file\n",
        "with open('./data/training-mltable-folder/MLTable', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "        paths:\n",
        "            - file: ./train.csv\n",
        "        transformations:\n",
        "            - read_delimited:\n",
        "                    delimiter: ','\n",
        "                    encoding: 'ascii'\n",
        "    \"\"\")\n",
        "\n",
        "    # MLTable definition file\n",
        "with open('./data/test-mltable-folder/MLTable', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "        paths:\n",
        "            - file: ./test.csv\n",
        "        transformations:\n",
        "            - read_delimited:\n",
        "                    delimiter: ','\n",
        "                    encoding: 'ascii'\n",
        "    \"\"\")\n",
        "    \n",
        "# MLTable definition file\n",
        "with open('./data/validation-mltable-folder/MLTable', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "        paths:\n",
        "            - file: ./validate.csv\n",
        "        transformations:\n",
        "            - read_delimited:\n",
        "                    delimiter: ','\n",
        "                    encoding: 'ascii'\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "gather": {
          "logged": 1669345066356
        }
      },
      "outputs": [],
      "source": [
        "# Create MLTables for training dataset\n",
        "\n",
        "my_training_data_input = Input(\n",
        "    type=AssetTypes.MLTABLE, path=\"./data/training-mltable-folder\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1669345074588
        }
      },
      "outputs": [],
      "source": [
        "# General job parameters\n",
        "compute_name = \"azureml-compute\"\n",
        "max_trials = 5\n",
        "exp_name = \"claim-prediction-experiment-2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the Classification Job\n",
        "After uploading the dataset, you can invoke AutoML to find the best ML pipeline to train a model on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "gather": {
          "logged": 1669345084537
        }
      },
      "outputs": [],
      "source": [
        "# Create the AutoML classification job with the related factory-function.\n",
        "\n",
        "classification_job = automl.classification(\n",
        "    compute=compute_name,\n",
        "    experiment_name=exp_name,\n",
        "    training_data=my_training_data_input,\n",
        "    target_column_name=\"target\",\n",
        "    primary_metric=\"accuracy\",\n",
        "    n_cross_validations=5,\n",
        "    enable_model_explainability=True,\n",
        "    tags={\"classification_task\": \"insurance-fraud\"},\n",
        ")\n",
        "\n",
        "# Limits are all optional\n",
        "classification_job.set_limits(\n",
        "    timeout_minutes=600,\n",
        "    trial_timeout_minutes=20,\n",
        "    max_trials=max_trials,\n",
        "    # max_concurrent_trials = 4,\n",
        "    # max_cores_per_trial: -1,\n",
        "    enable_early_termination=True,\n",
        ")\n",
        "\n",
        "# Training properties are optional\n",
        "classification_job.set_training(\n",
        "    blocked_training_algorithms=[\"LogisticRegression\"],\n",
        "    enable_onnx_compatible_models=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669345097301
        }
      },
      "outputs": [],
      "source": [
        "# Submit the AutoML job (CDLTLL: Is it ml_client.create_or_update(classification_job))\n",
        "returned_job = ml_client.jobs.create_or_update(\n",
        "    classification_job\n",
        ")  # submit the job to the backend\n",
        "\n",
        "print(f\"Created job: {returned_job}\")\n",
        "\n",
        "# Get a URL for the status of the job\n",
        "# returned_job.services[\"Studio\"].endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Launching the AutoML Job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This job is going to take close to 15 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669345537000
        }
      },
      "outputs": [],
      "source": [
        "ml_client.jobs.stream(returned_job.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669345673702
        }
      },
      "outputs": [],
      "source": [
        "# Get a URL for the status of the job\n",
        "returned_job.services[\"Studio\"].endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "gather": {
          "logged": 1669345675559
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zen_foot_z2cn39t9vt\n"
          ]
        }
      ],
      "source": [
        "print(returned_job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# It's optional to proceed to the sections below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve the Best Trial (Best Model's trial/run)\n",
        "Use the MLFLowClient to access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Trial.\n",
        "\n",
        "## Initialize MLFlow Client\n",
        "The models and artifacts that are produced by AutoML can be accessed via the MLFlow interface. \n",
        "Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\n",
        "\n",
        "*IMPORTANT*, you need to have installed the latest MLFlow packages with:\n",
        "\n",
        "    pip install azureml-mlflow\n",
        "\n",
        "    pip install mlflow\n",
        "\n",
        "### Obtain the tracking URI for MLFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669209834664
        }
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "# Obtain the tracking URL from MLClient\n",
        "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
        "    name=ml_client.workspace_name\n",
        ").mlflow_tracking_uri\n",
        "\n",
        "print(MLFLOW_TRACKING_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669209837847
        }
      },
      "outputs": [],
      "source": [
        "# Set the MLFLOW TRACKING URI\n",
        "\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "\n",
        "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1669209841266
        }
      },
      "outputs": [],
      "source": [
        "from mlflow.tracking.client import MlflowClient\n",
        "\n",
        "# Initialize MLFlow client\n",
        "mlflow_client = MlflowClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the AutoML parent Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1669209844263
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parent Run: \n",
            "<Run: data=<RunData: metrics={'AUC_macro': 0.5490186868098261,\n",
            " 'AUC_micro': 0.9419168915699154,\n",
            " 'AUC_weighted': 0.5490186868098261,\n",
            " 'accuracy': 0.9360261698193714,\n",
            " 'average_precision_score_macro': 0.5117692757642988,\n",
            " 'average_precision_score_micro': 0.9295816055434472,\n",
            " 'average_precision_score_weighted': 0.8904370258383925,\n",
            " 'balanced_accuracy': 0.5,\n",
            " 'f1_score_macro': 0.4834762412568109,\n",
            " 'f1_score_micro': 0.9360261698193714,\n",
            " 'f1_score_weighted': 0.9050998571251208,\n",
            " 'log_loss': 0.23782531949216668,\n",
            " 'matthews_correlation': 0.0,\n",
            " 'norm_macro_recall': 0.0,\n",
            " 'precision_score_macro': 0.4680130849096857,\n",
            " 'precision_score_micro': 0.9360261698193714,\n",
            " 'precision_score_weighted': 0.8761581666869324,\n",
            " 'recall_score_macro': 0.5,\n",
            " 'recall_score_micro': 0.9360261698193714,\n",
            " 'recall_score_weighted': 0.9360261698193714,\n",
            " 'weighted_accuracy': 0.9953316698607239}, params={}, tags={'automl_best_child_run_id': 'serene_goat_40s2k8j8yd_4',\n",
            " 'classification_task': 'sec',\n",
            " 'fit_time': '',\n",
            " 'iteration': '',\n",
            " 'mlflow.rootRunId': 'serene_goat_40s2k8j8yd',\n",
            " 'mlflow.runName': 'serene_goat_40s2k8j8yd',\n",
            " 'mlflow.user': 'Ezhil Vezhavendhan',\n",
            " 'model_explain_best_run_child_id': 'serene_goat_40s2k8j8yd_4',\n",
            " 'model_explain_run': 'best_run',\n",
            " 'pipeline_id': '',\n",
            " 'predicted_cost': '',\n",
            " 'run_algorithm': '',\n",
            " 'run_preprocessor': '',\n",
            " 'score': '',\n",
            " 'training_percent': ''}>, info=<RunInfo: artifact_uri='azureml://experiments/claim-prediction-experiment/runs/serene_goat_40s2k8j8yd/artifacts', end_time=1669209426803, experiment_id='b57f67c9-da73-47d3-9a59-3daea46a6cc7', lifecycle_stage='active', run_id='serene_goat_40s2k8j8yd', run_name='', run_uuid='serene_goat_40s2k8j8yd', start_time=1669208692947, status='FINISHED', user_id='374e1cf7-a5c7-4cc0-8fa9-7a5326e69453'>>\n"
          ]
        }
      ],
      "source": [
        "job_name = returned_job.name\n",
        "\n",
        "# Example if providing an specific Job name/ID\n",
        "# job_name = \"b4e95546-0aa1-448e-9ad6-002e3207b4fc\"\n",
        "\n",
        "# Get the parent run\n",
        "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
        "\n",
        "print(\"Parent Run: \")\n",
        "print(mlflow_parent_run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1669209847966
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'classification_task': 'sec', 'model_explain_run': 'best_run', 'pipeline_id': '', 'score': '', 'predicted_cost': '', 'fit_time': '', 'training_percent': '', 'iteration': '', 'run_preprocessor': '', 'run_algorithm': '', 'automl_best_child_run_id': 'serene_goat_40s2k8j8yd_4', 'model_explain_best_run_child_id': 'serene_goat_40s2k8j8yd_4', 'mlflow.rootRunId': 'serene_goat_40s2k8j8yd', 'mlflow.runName': 'serene_goat_40s2k8j8yd', 'mlflow.user': 'Ezhil Vezhavendhan'}\n"
          ]
        }
      ],
      "source": [
        "# Print parent run tags. 'automl_best_child_run_id' tag should be there.\n",
        "print(mlflow_parent_run.data.tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the AutoML best child run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1669209851216
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found best child run id:  serene_goat_40s2k8j8yd_4\n",
            "Best child run: \n",
            "<Run: data=<RunData: metrics={'AUC_macro': 0.5490186868098261,\n",
            " 'AUC_micro': 0.9419168915699154,\n",
            " 'AUC_weighted': 0.5490186868098261,\n",
            " 'accuracy': 0.9360261698193714,\n",
            " 'average_precision_score_macro': 0.5117692757642988,\n",
            " 'average_precision_score_micro': 0.9295816055434472,\n",
            " 'average_precision_score_weighted': 0.8904370258383925,\n",
            " 'balanced_accuracy': 0.5,\n",
            " 'f1_score_macro': 0.4834762412568109,\n",
            " 'f1_score_micro': 0.9360261698193714,\n",
            " 'f1_score_weighted': 0.9050998571251208,\n",
            " 'log_loss': 0.23782531949216668,\n",
            " 'matthews_correlation': 0.0,\n",
            " 'norm_macro_recall': 0.0,\n",
            " 'precision_score_macro': 0.4680130849096857,\n",
            " 'precision_score_micro': 0.9360261698193714,\n",
            " 'precision_score_weighted': 0.8761581666869324,\n",
            " 'recall_score_macro': 0.5,\n",
            " 'recall_score_micro': 0.9360261698193714,\n",
            " 'recall_score_weighted': 0.9360261698193714,\n",
            " 'weighted_accuracy': 0.9953316698607239}, params={}, tags={'mlflow.parentRunId': 'serene_goat_40s2k8j8yd',\n",
            " 'mlflow.rootRunId': 'serene_goat_40s2k8j8yd',\n",
            " 'mlflow.runName': 'dreamy_kitchen_n9kwbwvt',\n",
            " 'mlflow.source.name': 'automl_driver.py',\n",
            " 'mlflow.source.type': 'JOB',\n",
            " 'mlflow.user': 'Ezhil Vezhavendhan',\n",
            " 'model_explain_run_id': 'serene_goat_40s2k8j8yd_ModelExplain',\n",
            " 'model_explanation': 'True'}>, info=<RunInfo: artifact_uri='azureml://experiments/claim-prediction-experiment/runs/serene_goat_40s2k8j8yd_4/artifacts', end_time=1669209424929, experiment_id='b57f67c9-da73-47d3-9a59-3daea46a6cc7', lifecycle_stage='active', run_id='serene_goat_40s2k8j8yd_4', run_name='', run_uuid='serene_goat_40s2k8j8yd_4', start_time=1669209369894, status='FINISHED', user_id='374e1cf7-a5c7-4cc0-8fa9-7a5326e69453'>>\n"
          ]
        }
      ],
      "source": [
        "# Get the best model's child run\n",
        "\n",
        "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
        "print(\"Found best child run id: \", best_child_run_id)\n",
        "\n",
        "best_run = mlflow_client.get_run(best_child_run_id)\n",
        "\n",
        "print(\"Best child run: \")\n",
        "print(best_run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get best model run's metrics\n",
        "\n",
        "Access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1669209856912
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'precision_score_macro': 0.4680130849096857,\n",
              " 'accuracy': 0.9360261698193714,\n",
              " 'average_precision_score_micro': 0.9295816055434472,\n",
              " 'balanced_accuracy': 0.5,\n",
              " 'recall_score_macro': 0.5,\n",
              " 'recall_score_weighted': 0.9360261698193714,\n",
              " 'recall_score_micro': 0.9360261698193714,\n",
              " 'f1_score_macro': 0.4834762412568109,\n",
              " 'precision_score_micro': 0.9360261698193714,\n",
              " 'AUC_micro': 0.9419168915699154,\n",
              " 'matthews_correlation': 0.0,\n",
              " 'norm_macro_recall': 0.0,\n",
              " 'log_loss': 0.23782531949216668,\n",
              " 'AUC_weighted': 0.5490186868098261,\n",
              " 'precision_score_weighted': 0.8761581666869324,\n",
              " 'average_precision_score_macro': 0.5117692757642988,\n",
              " 'f1_score_micro': 0.9360261698193714,\n",
              " 'f1_score_weighted': 0.9050998571251208,\n",
              " 'weighted_accuracy': 0.9953316698607239,\n",
              " 'AUC_macro': 0.5490186868098261,\n",
              " 'average_precision_score_weighted': 0.8904370258383925}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_run.data.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "embedding.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "instance_type": "ml.t3.medium",
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
